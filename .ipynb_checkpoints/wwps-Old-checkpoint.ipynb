{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324cf946",
   "metadata": {},
   "source": [
    "# Welcome to \"What would presidents say?\"\n",
    "\n",
    "# Which presidents do you think like?\n",
    "We have access to all the US Presidential Speeches from April 30th, 1789 to Sept. 25th, 2019. Presidential speeches are an opportunity for Presidents to set the tone of the country, put forth their agenda, influence policy and sway public opinion.\n",
    "\n",
    "We're going to build a system in which given a random sentence as the input, the program outputs the top 3 similar sentences from different presidents.\n",
    "\n",
    "This reminds me of those WWJD aka What Would Jesus Do wrist bands that were popular back when I was in High School/University.\n",
    "\n",
    "Now we're going to create WWPS i.e. \"What would presidents say?\" - A pipeline that, when given a sentence, would spit out the top 3 similar sentences previoulsy uttered by different US presidents.\n",
    "\n",
    "Source data: https://www.kaggle.com/littleotter/united-states-presidential-speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8c72d",
   "metadata": {},
   "source": [
    "# Step i - Understanding the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c058387",
   "metadata": {},
   "source": [
    "The first thing we need to do is understand the type of problem we are solving. The main features of this problem are:\n",
    "- Unsupervised\n",
    "    - The data is not labelled and we don't have a test set to validate our results.\n",
    "- Text Similarity\n",
    "    - We need to compare whether one set of text with another and determine their similarity.\n",
    "- Information Retrieval \n",
    "    - We need to fetch relevant sources of information from a corpus just like a quer or search on a search engine.\n",
    "Now that we know that we understand which steps to take to develop a suitable algorithm.\n",
    "\n",
    "There are 2 main ways to analyse Text Similarity; Lexical Similarity and Semantical Similarity. We will select Semantical Similarity as in addition to syntax, the algorithm will consider context.\n",
    "\n",
    "The steps involved in Text Similarity:\n",
    "1. Text Normalization\n",
    "    - Tokenize the sentences.\n",
    "    - Develop a method that can be used for both the search_ and the corpus.\n",
    "2. Information Retrieval\n",
    "    - We need to define search_ and find a way to get input from the user.\n",
    "3. Feature Engineering\n",
    "    - Our options here include Bag of Words, TF-IDF and Word Vectorization\n",
    "    - The 2 options include Lexical \n",
    "4. Similarity Measure\n",
    "    - We need to find an optimal measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e5196a",
   "metadata": {},
   "source": [
    "# Step ii: Import Libraries and Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f3d2956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0efdba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus():\n",
    "    corpus_df = pd.read_csv('corpus.csv')\n",
    "    return corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e482d74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = read_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ef0acb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President</th>\n",
       "      <th>Party</th>\n",
       "      <th>transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Fellow Citizens of the Senate and the House of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Adams</td>\n",
       "      <td>Federalist</td>\n",
       "      <td>When it was first perceived, in early times, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas Jefferson</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "      <td>FRIENDS AND FELLOW-CITIZENS, Called upon to un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James Madison</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "      <td>Unwilling to depart from examples of the most ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Monroe</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "      <td>I should be destitute of feeling if I was not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>John Quincy Adams</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "      <td>AND NOW, FRIENDS AND COUNTRYMEN, if the wise a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Andrew Jackson</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Fellow Citizens: About to undertake the arduou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Martin Van Buren</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Fellow Citizens: The practice of all my predec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>William Harrison</td>\n",
       "      <td>Whig</td>\n",
       "      <td>Called from a retirement which I had supposed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>John Tyler</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>To the People of the United States Before my a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           President                  Party  \\\n",
       "0  George Washington           Unaffiliated   \n",
       "1         John Adams             Federalist   \n",
       "2   Thomas Jefferson  Democratic-Republican   \n",
       "3      James Madison  Democratic-Republican   \n",
       "4       James Monroe  Democratic-Republican   \n",
       "5  John Quincy Adams  Democratic-Republican   \n",
       "6     Andrew Jackson             Democratic   \n",
       "7   Martin Van Buren             Democratic   \n",
       "8   William Harrison                   Whig   \n",
       "9         John Tyler           Unaffiliated   \n",
       "\n",
       "                                         transcripts  \n",
       "0  Fellow Citizens of the Senate and the House of...  \n",
       "1  When it was first perceived, in early times, t...  \n",
       "2  FRIENDS AND FELLOW-CITIZENS, Called upon to un...  \n",
       "3  Unwilling to depart from examples of the most ...  \n",
       "4  I should be destitute of feeling if I was not ...  \n",
       "5  AND NOW, FRIENDS AND COUNTRYMEN, if the wise a...  \n",
       "6  Fellow Citizens: About to undertake the arduou...  \n",
       "7  Fellow Citizens: The practice of all my predec...  \n",
       "8  Called from a retirement which I had supposed ...  \n",
       "9  To the People of the United States Before my a...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6db9ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President</th>\n",
       "      <th>Party</th>\n",
       "      <th>transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Fellow Citizens of the Senate and the House of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Adams</td>\n",
       "      <td>Federalist</td>\n",
       "      <td>When it was first perceived, in early times, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas Jefferson</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "      <td>FRIENDS AND FELLOW-CITIZENS, Called upon to un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James Madison</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "      <td>Unwilling to depart from examples of the most ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Monroe</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "      <td>I should be destitute of feeling if I was not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           President                  Party  \\\n",
       "0  George Washington           Unaffiliated   \n",
       "1         John Adams             Federalist   \n",
       "2   Thomas Jefferson  Democratic-Republican   \n",
       "3      James Madison  Democratic-Republican   \n",
       "4       James Monroe  Democratic-Republican   \n",
       "\n",
       "                                         transcripts  \n",
       "0  Fellow Citizens of the Senate and the House of...  \n",
       "1  When it was first perceived, in early times, t...  \n",
       "2  FRIENDS AND FELLOW-CITIZENS, Called upon to un...  \n",
       "3  Unwilling to depart from examples of the most ...  \n",
       "4  I should be destitute of feeling if I was not ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.rename( columns={\"Unnamed: 0\" :\"President\"}, inplace=True )\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf19644",
   "metadata": {},
   "source": [
    "# Step 1: Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0eff9a",
   "metadata": {},
   "source": [
    "Removing stop words may harm the results since we are looking for similarities in sentences. So will try it **with** and **without stop words**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac67606",
   "metadata": {},
   "source": [
    "Reference: https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ff52a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e7929b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6b7a34c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fellow Citizens: About to undertake the arduous duties that I have been appointed to perform by the '"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenise words while ignoring punctuation\n",
    "test = corpus_df['transcripts'].iloc(0)[6][:100]\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5490c5e8",
   "metadata": {},
   "source": [
    "### Normalize a line of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8bb01bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "304e0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    \n",
    "    # Tokenise words while ignoring punctuation\n",
    "    text = re.sub(REPLACE_NO_SPACE, \" \", text)\n",
    "    text = re.sub(REPLACE_WITH_SPACE, \" \", text)\n",
    "    # Use the tokenization from nltk (word_tokenize)\n",
    "    \n",
    "    #tokeniser = RegexpTokenizer(REPLACE_NO_SPACE)\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Lowercase and lemmatise \n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    lemmas = [lemmatiser.lemmatize(token.lower(), pos='v') for token in tokens]\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a8b25801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_stop(text):\n",
    "    text = re.sub(REPLACE_NO_SPACE, \" \", text)\n",
    "    text = re.sub(REPLACE_WITH_SPACE, \" \", text)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Alternative for lemma and stop workds\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    lemmas = [lemmatiser.lemmatize(token.lower(), pos='v') for token in tokens if token not in stopword_list]\n",
    "\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "59e92f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 9)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalize(test)),len(normalize_stop(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fb532f52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['fellow',\n",
       "  'citizens',\n",
       "  'about',\n",
       "  'to',\n",
       "  'undertake',\n",
       "  'the',\n",
       "  'arduous',\n",
       "  'duties',\n",
       "  'that',\n",
       "  'i',\n",
       "  'have',\n",
       "  'be',\n",
       "  'appoint',\n",
       "  'to',\n",
       "  'perform',\n",
       "  'by',\n",
       "  'the'],\n",
       " ['fellow',\n",
       "  'citizens',\n",
       "  'about',\n",
       "  'undertake',\n",
       "  'arduous',\n",
       "  'duties',\n",
       "  'i',\n",
       "  'appoint',\n",
       "  'perform'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(test),normalize_stop(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7a6fc9",
   "metadata": {},
   "source": [
    "### Normalize the dataframe.column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ab3f7d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d95f41de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Fellow Citizens of the Senate and the House of...\n",
       "1    When it was first perceived, in early times, t...\n",
       "Name: transcripts, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.transcripts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "67a128d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(col):\n",
    "    new_column = [normalize(row) for row in col]  \n",
    "    return new_column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4b481122",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df['tokens'] = get_tokens(corpus_df.transcripts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "876af206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(col):\n",
    "    new_column = [normalize_stop(row) for row in col]  \n",
    "    return new_column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0ed7f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df['tokens_stop'] = get_tokens(corpus_df.transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1784dc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President</th>\n",
       "      <th>Party</th>\n",
       "      <th>transcripts</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Republican</td>\n",
       "      <td>By the President of the United States of Ameri...</td>\n",
       "      <td>[by, the, president, of, the, unite, state, of...</td>\n",
       "      <td>[by, president, unite, state, america, a, proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Harry S. Truman</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Mr. Speaker, Mr. President, Members of the Con...</td>\n",
       "      <td>[mr, speaker, mr, president, members, of, the,...</td>\n",
       "      <td>[mr, speaker, mr, president, members, congress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dwight D. Eisenhower</td>\n",
       "      <td>Republican</td>\n",
       "      <td>My friends, before I begin the expression of t...</td>\n",
       "      <td>[my, friends, before, i, begin, the, expressio...</td>\n",
       "      <td>[my, friends, i, begin, expression, thoughts, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Governor Stevenson, Senator Johnson, Mr. Butle...</td>\n",
       "      <td>[governor, stevenson, senator, johnson, mr, bu...</td>\n",
       "      <td>[governor, stevenson, senator, johnson, mr, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lyndon B. Johnson</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>On this hallowed ground, heroic deeds were per...</td>\n",
       "      <td>[on, this, hallow, grind, heroic, deeds, be, p...</td>\n",
       "      <td>[on, hallow, grind, heroic, deeds, perform, el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Richard M. Nixon</td>\n",
       "      <td>Republican</td>\n",
       "      <td>My Fellow Americans: I come before you tonight...</td>\n",
       "      <td>[my, fellow, americans, i, come, before, you, ...</td>\n",
       "      <td>[my, fellow, americans, i, come, tonight, cand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gerald Ford</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Mr. Chief Justice, my dear friends, my fellow ...</td>\n",
       "      <td>[mr, chief, justice, my, dear, friends, my, fe...</td>\n",
       "      <td>[mr, chief, justice, dear, friends, fellow, am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Jimmy Carter</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>I am Edwin Newman, moderator of this first deb...</td>\n",
       "      <td>[i, be, edwin, newman, moderator, of, this, fi...</td>\n",
       "      <td>[i, edwin, newman, moderator, first, debate, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ronald Reagan</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Thank you. Thank you very much. Thank you and ...</td>\n",
       "      <td>[thank, you, thank, you, very, much, thank, yo...</td>\n",
       "      <td>[thank, thank, much, thank, good, even, the, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>George H. W. Bush</td>\n",
       "      <td>Republican</td>\n",
       "      <td>I have many friends to thank tonight. I thank ...</td>\n",
       "      <td>[i, have, many, friends, to, thank, tonight, i...</td>\n",
       "      <td>[i, many, friends, thank, tonight, i, thank, v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               President       Party  \\\n",
       "30    Theodore Roosevelt  Republican   \n",
       "31       Harry S. Truman  Democratic   \n",
       "32  Dwight D. Eisenhower  Republican   \n",
       "33       John F. Kennedy  Democratic   \n",
       "34     Lyndon B. Johnson  Democratic   \n",
       "35      Richard M. Nixon  Republican   \n",
       "36           Gerald Ford  Republican   \n",
       "37          Jimmy Carter  Democratic   \n",
       "38         Ronald Reagan  Republican   \n",
       "39     George H. W. Bush  Republican   \n",
       "\n",
       "                                          transcripts  \\\n",
       "30  By the President of the United States of Ameri...   \n",
       "31  Mr. Speaker, Mr. President, Members of the Con...   \n",
       "32  My friends, before I begin the expression of t...   \n",
       "33  Governor Stevenson, Senator Johnson, Mr. Butle...   \n",
       "34  On this hallowed ground, heroic deeds were per...   \n",
       "35  My Fellow Americans: I come before you tonight...   \n",
       "36  Mr. Chief Justice, my dear friends, my fellow ...   \n",
       "37  I am Edwin Newman, moderator of this first deb...   \n",
       "38  Thank you. Thank you very much. Thank you and ...   \n",
       "39  I have many friends to thank tonight. I thank ...   \n",
       "\n",
       "                                               tokens  \\\n",
       "30  [by, the, president, of, the, unite, state, of...   \n",
       "31  [mr, speaker, mr, president, members, of, the,...   \n",
       "32  [my, friends, before, i, begin, the, expressio...   \n",
       "33  [governor, stevenson, senator, johnson, mr, bu...   \n",
       "34  [on, this, hallow, grind, heroic, deeds, be, p...   \n",
       "35  [my, fellow, americans, i, come, before, you, ...   \n",
       "36  [mr, chief, justice, my, dear, friends, my, fe...   \n",
       "37  [i, be, edwin, newman, moderator, of, this, fi...   \n",
       "38  [thank, you, thank, you, very, much, thank, yo...   \n",
       "39  [i, have, many, friends, to, thank, tonight, i...   \n",
       "\n",
       "                                          tokens_stop  \n",
       "30  [by, president, unite, state, america, a, proc...  \n",
       "31  [mr, speaker, mr, president, members, congress...  \n",
       "32  [my, friends, i, begin, expression, thoughts, ...  \n",
       "33  [governor, stevenson, senator, johnson, mr, bu...  \n",
       "34  [on, hallow, grind, heroic, deeds, perform, el...  \n",
       "35  [my, fellow, americans, i, come, tonight, cand...  \n",
       "36  [mr, chief, justice, dear, friends, fellow, am...  \n",
       "37  [i, edwin, newman, moderator, first, debate, 1...  \n",
       "38  [thank, thank, much, thank, good, even, the, s...  \n",
       "39  [i, many, friends, thank, tonight, i, thank, v...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df[30:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70082b4",
   "metadata": {},
   "source": [
    "# Step 3:  Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "24c86e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_matrix(documents, feature_type='frequency', ngram_range=(1, 1), min_df=0.0, max_df=1.0):\n",
    "    \n",
    "    feature_type = feature_type.lower().strip()\n",
    "    if feature_type == 'binary':\n",
    "        vectorizer = CountVectorizer(binary=True, min_df=min_df,max_df=max_df, ngram_range=ngram_range)                 \n",
    "    elif feature_type == 'frequency':\n",
    "        vectorizer = CountVectorizer(binary=False, min_df=min_df, max_df=max_df, ngram_range=ngram_range)\n",
    "    elif feature_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df,ngram_range=ngram_range)\n",
    "    else:\n",
    "        raise Exception(\"Wrong feature type entered. Possible values: 'binary', 'frequency','tfidf'\")\n",
    "    feature_matrix = vectorizer.fit_transform(documents).astype(float)\n",
    "    return vectorizer, feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8014c691",
   "metadata": {},
   "source": [
    "# Step 4: Text Similarity (Lexical or Semantic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c88db",
   "metadata": {},
   "source": [
    "Improvement. We can train from a much larger data set. E.g. some book excerpts or twitter feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5b3f8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "enter_sentence = [\"It's been a long time since we've been to the park to play with the dog.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0d1cdb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5b71e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interface lemma tokenizer from nltk with sklearn\n",
    "class LemmaTokenizer:\n",
    "    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`']\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.ignore_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d939880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=LemmaTokenizer()\n",
    "token_stop = tokenizer(' '.join(stop_words))\n",
    "\n",
    "search_terms = 'red tomato'\n",
    "documents = ['cars drive on the road', 'tomatoes are actually fruit']\n",
    "\n",
    "# Create TF-idf model\n",
    "vectorizer = TfidfVectorizer(stop_words=token_stop, \n",
    "                              tokenizer=tokenizer)\n",
    "doc_vectors = vectorizer.fit_transform([search_terms] + documents)\n",
    "\n",
    "# Calculate similarity\n",
    "cosine_similarities = linear_kernel(doc_vectors[0:1], doc_vectors).flatten()\n",
    "document_scores = [item.item() for item in cosine_similarities[1:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4e248ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.2867109723804671]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16e45b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4fe53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74689e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec6b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81c54f5e",
   "metadata": {},
   "source": [
    "### Normalize and Extract Features for user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a43f93fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1023706616.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/m6/fxj587w93gn106xqhsxs8g7r0000gn/T/ipykernel_40668/1023706616.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    type='binary',\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "norm_sentence = normalize(enter_sentence)\n",
    "tfidf_vectorizer, tfidf_features = build_feature_matrix(norm_sentence,\n",
    "                                                        feature_\n",
    "                                                        type='binary',\n",
    "                                                        ngram_range=(1, 1),\n",
    "                                                        min_df=0.0, max_\n",
    "                                                        df=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8d442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer, tfidf_features = build_feature_matrix(norm_sentence,\n",
    "                                                        feature_\n",
    "                                                        type='binary',\n",
    "                                                        ngram_range=(1, 1),\n",
    "                                                        min_df=0.0, max_\n",
    "                                                        df=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6144ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a4251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb278e98",
   "metadata": {},
   "source": [
    "# Step 5: Term Similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
